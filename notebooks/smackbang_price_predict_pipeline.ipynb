{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc1dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fc584e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../dataset/Data_Train.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../dataset/Data_Train.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/smackbang/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/smackbang/lib/python3.8/site-packages/pandas/io/excel/_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    456\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/smackbang/lib/python3.8/site-packages/pandas/io/excel/_base.py:1376\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1381\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/smackbang/lib/python3.8/site-packages/pandas/io/excel/_base.py:1250\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1248\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1253\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1254\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/smackbang/lib/python3.8/site-packages/pandas/io/common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../dataset/Data_Train.xlsx'"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('../../dataset/Data_Train.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fc061e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe441be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel('../../dataset/Test_set.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb81868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309cacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required library\n",
    "#from geopy.geocoders import Nominatim\n",
    "\n",
    "# Initialize Nominatim API\n",
    "#geolocator = Nominatim(user_agent=\"MyApp\")\n",
    "\n",
    "\n",
    "#for index, row in df.iterrows():\n",
    "#    location = geolocator.geocode(row['Source'])\n",
    "#    df.loc[index, \"origin_one_latitude\"] = location.latitude\n",
    "#    df.loc[index, \"origin_one_longitude\"] = location.longitude\n",
    "#    location = geolocator.geocode(row['Destination'])\n",
    "#    df.loc[index, \"origin_two_latitude\"] = location.latitude\n",
    "#    df.loc[index, \"origin_two_longitude\"] = location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f896898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70758aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFormatter(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # stateless transformer\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # assumes X is a DataFrame\n",
    "        Xdate = X.apply(pd.to_datetime)\n",
    "        return Xdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08301a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pipe = DateFormatter()\n",
    "date_pipe.fit_transform(df[['Date_of_Journey', 'Dep_Time', 'Arrival_Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ff7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateEncoder(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        new_cols = []\n",
    "        for col in X_copy.columns: \n",
    "            new_cols.append(X_copy[col].dt.month)\n",
    "            new_cols.append(X_copy[col].dt.day)\n",
    "        return pd.concat(new_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pipe = Pipeline([\n",
    "        ('date_format', DateFormatter()),\n",
    "        ('date_enc', DateEncoder())\n",
    "    ])\n",
    "date_pipe.fit_transform(df[['Date_of_Journey', 'Dep_Time', 'Arrival_Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcabfc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeFeaturesEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Extract the day of week (dow), the hour, the month and the year from a time column.\"\"\"\n",
    "\n",
    "    def __init__(self, time_zone_name='UTC'):\n",
    "#         self.time_column = time_column\n",
    "        self.time_zone_name = time_zone_name\n",
    "\n",
    "    def extract_time_features(self, X):\n",
    "        timezone_name = self.time_zone_name\n",
    "#         time_column = self.time_column\n",
    "        df = X.copy()\n",
    "#         df.index = df[time_column].apply(pd.to_datetime)\n",
    "        old_cols = list(df.columns)\n",
    "        for col in old_cols:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "            df[col] = df[col].dt.tz_localize(timezone_name)\n",
    "            df[f\"{col}_hour\"] = df[col].dt.hour\n",
    "            df[f\"{col}_minute\"] = df[col].dt.minute\n",
    "        df.drop(columns=old_cols, inplace=True)\n",
    "        return df\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Returns a copy of the DataFrame X with only four columns: 'hour', 'month'\"\"\"\n",
    "        return self.extract_time_features(X)#.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedabc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_enc = TimeFeaturesEncoder()\n",
    "time_features = time_enc.fit_transform(df[['Dep_Time', 'Arrival_Time']])\n",
    "time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_vectorized(df,\n",
    "                         start_lat=\"origin_one_latitude\",\n",
    "                         start_lon=\"origine_one_longitude\",\n",
    "                         end_lat=\"origin_two_latitude\",\n",
    "                         end_lon=\"origin_two_longitude\"):\n",
    "    \"\"\" \n",
    "        Calculates the great circle distance between two points \n",
    "        on the earth (specified in decimal degrees).\n",
    "        Vectorized version of the haversine distance for pandas df.\n",
    "        Computes the distance in kms.\n",
    "    \"\"\"\n",
    "\n",
    "    lat_1_rad, lon_1_rad = np.radians(df[start_lat].astype(float)), np.radians(\n",
    "        df[start_lon].astype(float))\n",
    "    lat_2_rad, lon_2_rad = np.radians(df[end_lat].astype(float)), np.radians(\n",
    "        df[end_lon].astype(float))\n",
    "    dlon = lon_2_rad - lon_1_rad\n",
    "    dlat = lat_2_rad - lat_1_rad\n",
    "\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat_1_rad) * np.cos(lat_2_rad) * np.sin(\n",
    "        dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371 * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e269c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DistanceTransformer\n",
    "class DistanceTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "        Computes the haversine distance between two GPS points.\n",
    "        Returns a copy of the DataFrame X with only one column: 'distance'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 start_lat=\"origin_one_latitude\",\n",
    "                 start_lon=\"origin_one_longitude\",\n",
    "                 end_lat=\"origin_two_latitude\",\n",
    "                 end_lon=\"origin_two_longitude\"):\n",
    "        self.start_lat = start_lat\n",
    "        self.start_lon = start_lon\n",
    "        self.end_lat = end_lat\n",
    "        self.end_lon = end_lon\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        X_ = X.copy()\n",
    "        X_[\"distance\"] = haversine_vectorized(X_,\n",
    "                                              start_lat=self.start_lat,\n",
    "                                              start_lon=self.start_lon,\n",
    "                                              end_lat=self.end_lat,\n",
    "                                              end_lon=self.end_lon)\n",
    "        return X_[['distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a28ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_transformer = DistanceTransformer(\"origin_one_latitude\", \"origin_one_longitude\",\"origin_two_latitude\",\"origin_two_longitude\")\n",
    "dist_df = dist_transformer.fit_transform(df[[\"origin_one_latitude\", \"origin_one_longitude\",\"origin_two_latitude\",\"origin_two_longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a6a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_process(df):\n",
    "    duration_obj = df.values.reshape(-1)\n",
    "    print(duration_obj)\n",
    "    col = 'duration'\n",
    "    for i in range(len(duration_obj)):\n",
    "        if len(duration_obj[i].split(' ')) == 2:\n",
    "            pass\n",
    "        else:\n",
    "            if 'h' in duration_obj[i]:\n",
    "                duration_obj[i] = duration_obj[i] + ' ' + '0m'\n",
    "            else:\n",
    "                duration_obj[i] = '0h' + ' ' + duration_obj[i]\n",
    "    df = pd.DataFrame(duration_obj, dtype='str')\n",
    "    df[f'{col}_hour'] = df[0].str.split(\"h \", n=1,\n",
    "                                          expand=True)[0].astype('int64')\n",
    "    df[f'{col}_min'] = df[0].str.split(\n",
    "        \" \", n=2, expand=True)[1].str.strip('m').astype('int64')\n",
    "    df.drop(columns=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = FunctionTransformer(duration_process)\n",
    "transformer.fit_transform(df['Duration']) #df['Duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe332de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_preproc_pipeline():\n",
    "    # create date pipeline\n",
    "    date_pipe = Pipeline([\n",
    "        ('date_format', DateFormatter()),\n",
    "        ('date_enc', DateEncoder())\n",
    "    ])\n",
    "        \n",
    "    # create time pipeline\n",
    "    time_pipe = Pipeline([\n",
    "        ('time_enc', TimeFeaturesEncoder()),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    \n",
    "    dist_pipe = Pipeline([\n",
    "        ('dist_trans', DistanceTransformer()),\n",
    "        ('stdscaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    duration_pipe = FunctionTransformer(duration_process)\n",
    "    \n",
    "    preproc_pipe = ColumnTransformer([('date_pipe', date_pipe, ['Date_of_Journey', 'Dep_Time', 'Arrival_Time']),\n",
    "                       ('time_pipe', time_pipe, ['Dep_Time', 'Arrival_Time']), \n",
    "                       ('dist_pipe', dist_pipe, [\"origin_one_latitude\", \"origin_one_longitude\",\"origin_two_latitude\",\"origin_two_longitude\"]),\n",
    "                       ('duration_pipe', duration_pipe, ['Duration'])\n",
    "                                     ], remainder='drop')\n",
    "    final_pipe = Pipeline([\n",
    "        ('preproc', preproc_pipe),\n",
    "        ('stdscaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "# display time pipeline\n",
    "    return final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1bb0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_pipeline = set_preproc_pipeline()\n",
    "preproc_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0dea73",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = Pipeline([\n",
    "        ('preproc', preproc_pipeline),\n",
    "        ('random_forest_model', RandomForestRegressor())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37730a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X and y\n",
    "y = df[\"Price\"]\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "preproc_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b92e3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement train() function\n",
    "def train(X_train, y_train, pipeline):\n",
    "    '''returns a trained pipelined model'''\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dfac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement evaluate() function\n",
    "def evaluate(X_test, y_test, pipeline):\n",
    "    '''returns the value of the RMSE'''\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    rmse = compute_rmse(y_pred, y_test)\n",
    "    print(rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f65fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pipeline\n",
    "trained_model = train(X_train, y_train, final_pipe)\n",
    "\n",
    "## saving model to .joblib\n",
    "joblib.dump(trained_model,'rf_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the pipeline\n",
    "rmse = evaluate(X_test, y_test, final_pipe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
